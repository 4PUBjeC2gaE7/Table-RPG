{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "Run this section to call imports and run calibration. This section takes about 30 seconds to operate and requires input from the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen not found\n",
      "\n",
      "\tThreshold: 130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from ScreenRemap import runCalibration\n",
    "\n",
    "pts, frmMask = runCalibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define blob parameters, search\n",
    "blobParams = cv2.SimpleBlobDetector_Params()\n",
    "blobParams.filterByArea = True\n",
    "blobParams.filterByColor = False\n",
    "blobParams.filterByInertia = False\n",
    "blobParams.filterByCircularity = False\n",
    "blobParams.filterByConvexity = False\n",
    "blobParams.minArea = 2000\n",
    "blobParams.maxArea = 50000\n",
    "myBlob = cv2.SimpleBlobDetector_create(blobParams)\n",
    "\n",
    "# define auras look-up\n",
    "myAuras = { 'One':None, 'Two':None, 'Water': None, 'Fire':None}\n",
    "for select in myAuras.keys():\n",
    "    imOver = cv2.imread(f\".\\\\auras\\\\{select} Aura.png\").astype(float)\n",
    "    imAlpha = cv2.imread(f\".\\\\auras\\\\{select} Aura - Alpha.png\").astype(float)\n",
    "    imAlpha = imAlpha / imAlpha.max()\n",
    "    myAuras[select] = (imOver, imAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawAura(imDst, coords, select):\n",
    "    global myAuras\n",
    "    imSrc = myAuras[select][0]\n",
    "    imAlpha = myAuras[select][1]\n",
    "\n",
    "    # calculate positions\n",
    "    Oy, Ox, _ = imSrc.shape\n",
    "    top = int (coords[1] - (Oy / 2))\n",
    "    bottom = top + Oy\n",
    "    left = int (coords[0] - (Ox / 2))\n",
    "    right = left + Ox\n",
    "\n",
    "    print(f'\\ttop:{top}\\tbottom:{bottom}\\n\\tleft:{left}\\tright:{right}')\n",
    "    # too far up\n",
    "    if top < 0:\n",
    "        Iy_start = 0\n",
    "        Oy_start = abs(top)\n",
    "    else:\n",
    "        Iy_start = top\n",
    "        Oy_start = 0\n",
    "    # too far down\n",
    "    if bottom > imDst.shape[0]:\n",
    "        Iy_stop = imDst.shape[0]\n",
    "        Oy_stop = Oy - (bottom - Iy_stop)\n",
    "    else:\n",
    "        Iy_stop = bottom\n",
    "        Oy_stop = Oy\n",
    "    # too far left\n",
    "    if left < 0:\n",
    "        Ix_start = 0\n",
    "        Ox_start = abs(left)\n",
    "    else:\n",
    "        Ix_start = left\n",
    "        Ox_start = 0\n",
    "    # too far right\n",
    "    if right > imDst.shape[1]:  \n",
    "        Ix_stop = imDst.shape[1]\n",
    "        Ox_stop = Ox - (right - Ix_stop)\n",
    "    else:\n",
    "        Ix_stop = right\n",
    "        Ox_stop = Ox\n",
    "\n",
    "    imSubOver = imSrc[Oy_start:Oy_stop, Ox_start:Ox_stop]\n",
    "    imSub = imDst[Iy_start:Iy_stop, Ix_start:Ix_stop].astype(float)\n",
    "    if imAlpha is not None:\n",
    "        imSubOver *= imAlpha[Oy_start:Oy_stop, Ox_start:Ox_stop]\n",
    "        imSub *= 1 - imAlpha[Oy_start:Oy_stop, Ox_start:Ox_stop]\n",
    "    imSub = cv2.add(imSubOver, imSub)\n",
    "    imDst[Iy_start:Iy_stop, Ix_start:Ix_stop] = imSub.astype(np.uint8)\n",
    "\n",
    "    return imDst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Homography\n",
    "This section generates the homographic warp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sW = 1280\n",
    "sH = 720\n",
    "winMain = 'Reference Screen'\n",
    "winLive = 'Live View'\n",
    "\n",
    "H, ret = cv2.findHomography(np.array(pts), np.array([[0, sH],[0, 0],[sW, 0],[sW, sH]]))\n",
    "\n",
    "# generate base image\n",
    "vid = cv2.VideoCapture(0)\n",
    "imSrc = cv2.imread('background.png')\n",
    "imOut = imSrc.copy()\n",
    "cv2.imshow(winMain, imSrc)\n",
    "cv2.waitKey(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frmCurr = vid.read()\n",
    "if ret:\n",
    "    frmCurr = cv2.warpPerspective(frmCurr, H, (sW, sH))\n",
    "    frmDiff = imOut.copy()\n",
    "    frmCurr = cv2.cvtColor(frmCurr, cv2.COLOR_BGR2GRAY)\n",
    "    frmDiff = cv2.cvtColor(frmDiff, cv2.COLOR_BGR2GRAY)\n",
    "    frmDiff = cv2.GaussianBlur(frmDiff, (17, 17), 0)\n",
    "    cv2.subtract(frmDiff, frmCurr, frmDiff)\n",
    "    frmDiff = cv2.GaussianBlur(frmDiff, (19, 19), 0)\n",
    "    cv2.imshow('test',frmDiff)\n",
    "    cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold\n",
    "This code applies a few morphological transforms to resolve the difference between the reference image and the capture.\n",
    "The results are presented as a grayscale difference. White is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frmThres = frmDiff.copy()\n",
    "frmThres = cv2.GaussianBlur(frmThres, (27, 27), 0)\n",
    "cv2.multiply(frmThres, 255/frmThres.max(), frmThres)\n",
    "frmThres = cv2.erode(frmThres,np.ones(19, np.uint8))\n",
    "cv2.medianBlur(frmThres, 23, frmThres)\n",
    "# display image\n",
    "cv2.imshow('test',frmThres)\n",
    "cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Analysis Test\n",
    "This code uses blob analysis to identify discrete objects in the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmath import inf\n",
    "\n",
    "frmTest = frmThres.copy()\n",
    "_, frmTest = cv2.threshold(frmTest, 100, 255, cv2.THRESH_BINARY)\n",
    "if frmTest.max() != frmTest.min():\n",
    "    frmTest = frmTest.max() - frmTest\n",
    "else:\n",
    "    frmTest[:,:] = 255\n",
    "# add border to allow on-edge blob detect\n",
    "cv2.rectangle(frmTest, (0,0), (sW-1,sH-1), 255, 8)\n",
    "\n",
    "keyPoints = myBlob.detect(frmTest)\n",
    "\n",
    "frmTest = cv2.drawKeypoints(frmTest, keyPoints, np.array([]),\n",
    "                            (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('test',frmTest)\n",
    "cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay Test\n",
    "This section applies overlays to the base image where objects are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points found: 2\n",
      "Point   0: [974.7595 490.9661]\n",
      "\ttop:390\tbottom:590\n",
      "\tleft:924\tright:1024\n",
      "Point   1: [453.42896 220.8676 ]\n",
      "\ttop:120\tbottom:320\n",
      "\tleft:403\tright:503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPts = cv2.KeyPoint_convert(keyPoints)\n",
    "\n",
    "try:\n",
    "    print(f'Points found: {myPts.shape[0]}')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "imOut = imSrc.copy()\n",
    "for idx, pt in enumerate(myPts):\n",
    "    print(f'Point {idx:-3d}: {pt}')\n",
    "    imOut = drawAura(imOut, pt, list(myAuras.keys())[idx % len(myAuras.keys())])\n",
    "\n",
    "cv2.imshow(winMain, imOut)\n",
    "cv2.waitKey(250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
